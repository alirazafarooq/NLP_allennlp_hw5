{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import *\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "from overrides import overrides\n",
    "\n",
    "from allennlp.data import Instance\n",
    "from allennlp.data.token_indexers import TokenIndexer\n",
    "from allennlp.data.tokenizers import Token\n",
    "from allennlp.nn import util as nn_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(dict):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "    \n",
    "    def set(self, key, val):\n",
    "        self[key] = val\n",
    "        setattr(self, key, val)\n",
    "        \n",
    "config = Config(\n",
    "    testing=True,\n",
    "    seed=1,\n",
    "    batch_size=64,\n",
    "    lr=3e-4,\n",
    "    epochs=2,\n",
    "    hidden_sz=64,\n",
    "    max_seq_len=100, # necessary to limit memory usage\n",
    "    max_vocab_size=100000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.common.checks import ConfigurationError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path(\"./data\") / \"jigsaw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set random seed manually to replicate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fd888e63b70>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.vocabulary import Vocabulary\n",
    "from allennlp.data.dataset_readers import DatasetReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = [\"toxic\", \"severe_toxic\", \"obscene\",\n",
    "              \"threat\", \"insult\", \"identity_hate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.fields import TextField, MetadataField, ArrayField\n",
    "\n",
    "class JigsawDatasetReader(DatasetReader):\n",
    "    def __init__(self, tokenizer: Callable[[str], List[str]]=lambda x: x.split(),\n",
    "                 token_indexers: Dict[str, TokenIndexer] = None,\n",
    "                 max_seq_len: Optional[int]=config.max_seq_len) -> None:\n",
    "        super().__init__(lazy=False)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.token_indexers = token_indexers or {\"tokens\": SingleIdTokenIndexer()}\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "    @overrides\n",
    "    def text_to_instance(self, tokens: List[Token], id: str=None,\n",
    "                         labels: np.ndarray=None) -> Instance:\n",
    "        sentence_field = TextField(tokens, self.token_indexers)\n",
    "        fields = {\"tokens\": sentence_field}\n",
    "        \n",
    "        id_field = MetadataField(id)\n",
    "        fields[\"id\"] = id_field\n",
    "        \n",
    "        if labels is None:\n",
    "            labels = np.zeros(len(label_cols))\n",
    "        label_field = ArrayField(array=labels)\n",
    "        fields[\"label\"] = label_field\n",
    "\n",
    "        return Instance(fields)\n",
    "    \n",
    "    @overrides\n",
    "    def _read(self, file_path: str) -> Iterator[Instance]:\n",
    "        df = pd.read_csv(file_path)\n",
    "        if config.testing: df = df.head(1000)\n",
    "        for i, row in df.iterrows():\n",
    "            yield self.text_to_instance(\n",
    "                [Token(x) for x in self.tokenizer(row[\"comment_text\"])],\n",
    "                row[\"id\"], row[label_cols].values,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare token handlers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the spacy tokenizer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.tokenizers.word_splitter import SpacyWordSplitter\n",
    "from allennlp.data.token_indexers.elmo_indexer import ELMoCharacterMapper, ELMoTokenCharactersIndexer\n",
    "\n",
    "# the token indexer is responsible for mapping tokens to integers\n",
    "token_indexer = ELMoTokenCharactersIndexer()\n",
    "\n",
    "def tokenizer(x: str):\n",
    "    return [w.text for w in\n",
    "            SpacyWordSplitter(language='en_core_web_sm', \n",
    "                              pos_tags=False).split_words(x)[:config.max_seq_len]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = JigsawDatasetReader(\n",
    "    tokenizer=tokenizer,\n",
    "    token_indexers={\"tokens\": token_indexer}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "267it [00:01, 149.56it/s]\n",
      "251it [00:01, 248.04it/s]\n"
     ]
    }
   ],
   "source": [
    "train_ds, test_ds = (reader.read(DATA_ROOT / fname) for fname in [\"train.csv\", \"test_proced.csv\"])\n",
    "val_ds = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "267"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<allennlp.data.instance.Instance at 0x7fd8463776d8>,\n",
       " <allennlp.data.instance.Instance at 0x7fd8463de748>,\n",
       " <allennlp.data.instance.Instance at 0x7fd8463b59b0>,\n",
       " <allennlp.data.instance.Instance at 0x7fd84645d470>,\n",
       " <allennlp.data.instance.Instance at 0x7fd84644f9b0>,\n",
       " <allennlp.data.instance.Instance at 0x7fd846447400>,\n",
       " <allennlp.data.instance.Instance at 0x7fd846440390>,\n",
       " <allennlp.data.instance.Instance at 0x7fd846431828>,\n",
       " <allennlp.data.instance.Instance at 0x7fd8477b1828>,\n",
       " <allennlp.data.instance.Instance at 0x7fd8477b6940>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': [Explanation,\n",
       "  Why,\n",
       "  the,\n",
       "  edits,\n",
       "  made,\n",
       "  under,\n",
       "  my,\n",
       "  username,\n",
       "  Hardcore,\n",
       "  Metallica,\n",
       "  Fan,\n",
       "  were,\n",
       "  reverted,\n",
       "  ?,\n",
       "  They,\n",
       "  were,\n",
       "  n't,\n",
       "  vandalisms,\n",
       "  ,,\n",
       "  just,\n",
       "  closure,\n",
       "  on,\n",
       "  some,\n",
       "  GAs,\n",
       "  after,\n",
       "  I,\n",
       "  voted,\n",
       "  at,\n",
       "  New,\n",
       "  York,\n",
       "  Dolls,\n",
       "  FAC,\n",
       "  .,\n",
       "  And,\n",
       "  please,\n",
       "  do,\n",
       "  n't,\n",
       "  remove,\n",
       "  the,\n",
       "  template,\n",
       "  from,\n",
       "  the,\n",
       "  talk,\n",
       "  page,\n",
       "  since,\n",
       "  I,\n",
       "  'm,\n",
       "  retired,\n",
       "  now.89.205.38.27],\n",
       " '_token_indexers': {'tokens': <allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer at 0x7fd8483146a0>},\n",
       " '_indexed_tokens': None,\n",
       " '_indexer_name_to_indexed_token': None}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(train_ds[0].fields[\"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need to build the vocab: all that is handled by the token indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The iterator is responsible for batching the data and preparing it for input into the model. We'll use the BucketIterator that batches text sequences of smilar lengths together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.iterators import BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = BucketIterator(batch_size=config.batch_size, \n",
    "                          sorting_keys=[(\"tokens\", \"num_tokens\")],\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to tell the iterator how to numericalize the text data. We do this by passing the vocabulary to the iterator. This step is easy to forget so be careful! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator.index_with(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(iterator(train_ds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': {'tokens': tensor([[[259,  73, 112,  ..., 261, 261, 261],\n",
       "           [259, 100,  98,  ..., 261, 261, 261],\n",
       "           [259, 112, 111,  ..., 261, 261, 261],\n",
       "           ...,\n",
       "           [  0,   0,   0,  ...,   0,   0,   0],\n",
       "           [  0,   0,   0,  ...,   0,   0,   0],\n",
       "           [  0,   0,   0,  ...,   0,   0,   0]],\n",
       "  \n",
       "          [[259, 118, 260,  ..., 261, 261, 261],\n",
       "           [259, 115, 260,  ..., 261, 261, 261],\n",
       "           [259,  98, 260,  ..., 261, 261, 261],\n",
       "           ...,\n",
       "           [  0,   0,   0,  ...,   0,   0,   0],\n",
       "           [  0,   0,   0,  ...,   0,   0,   0],\n",
       "           [  0,   0,   0,  ...,   0,   0,   0]],\n",
       "  \n",
       "          [[259,  74, 260,  ..., 261, 261, 261],\n",
       "           [259,  71,  74,  ..., 261, 261, 261],\n",
       "           [259,  74,  85,  ..., 261, 261, 261],\n",
       "           ...,\n",
       "           [  0,   0,   0,  ...,   0,   0,   0],\n",
       "           [  0,   0,   0,  ...,   0,   0,   0],\n",
       "           [  0,   0,   0,  ...,   0,   0,   0]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[259,  35, 260,  ..., 261, 261, 261],\n",
       "           [259,  81, 109,  ..., 261, 261, 261],\n",
       "           [259, 101, 112,  ..., 261, 261, 261],\n",
       "           ...,\n",
       "           [  0,   0,   0,  ...,   0,   0,   0],\n",
       "           [  0,   0,   0,  ...,   0,   0,   0],\n",
       "           [  0,   0,   0,  ...,   0,   0,   0]],\n",
       "  \n",
       "          [[259,  85, 105,  ..., 261, 261, 261],\n",
       "           [259, 117, 105,  ..., 261, 261, 261],\n",
       "           [259, 106, 116,  ..., 261, 261, 261],\n",
       "           ...,\n",
       "           [  0,   0,   0,  ...,   0,   0,   0],\n",
       "           [  0,   0,   0,  ...,   0,   0,   0],\n",
       "           [  0,   0,   0,  ...,   0,   0,   0]],\n",
       "  \n",
       "          [[259, 110, 112,  ..., 261, 261, 261],\n",
       "           [259, 106, 111,  ..., 261, 261, 261],\n",
       "           [259,  85, 105,  ..., 261, 261, 261],\n",
       "           ...,\n",
       "           [  0,   0,   0,  ...,   0,   0,   0],\n",
       "           [  0,   0,   0,  ...,   0,   0,   0],\n",
       "           [  0,   0,   0,  ...,   0,   0,   0]]])},\n",
       " 'id': ['00397b264deba890',\n",
       "  '0097dd5c29bf7a15',\n",
       "  '0084d905b6f19f2b',\n",
       "  '0020e7119b96eeeb',\n",
       "  '003910ffa2f50517',\n",
       "  '0040017ef6277334',\n",
       "  '00229d44f41f3acb',\n",
       "  '00a1aabcab9d44a0',\n",
       "  '003f698d06c9b180',\n",
       "  '0071cd1ca07040ab',\n",
       "  '00637960a7ec3436',\n",
       "  '0044cf18cc2655b3',\n",
       "  '006cf8c9f4cc4d57',\n",
       "  '001c557175094f10',\n",
       "  '00562e78e0b34102',\n",
       "  '00803f08f55bdcad',\n",
       "  '005ba6af463ab6cf',\n",
       "  '00a98913b0b8ba34',\n",
       "  '0009801bd85e5806',\n",
       "  '00031b1e95af7921',\n",
       "  '0035d638ba684122',\n",
       "  '007ecbb379c4a861',\n",
       "  '00604eb295a1dbf2',\n",
       "  '00958dec64c33224',\n",
       "  '000eefc67a2c930f',\n",
       "  '003caacc6ce6c9e9',\n",
       "  '001dc38a83d420cf',\n",
       "  '008e0818dde894fb',\n",
       "  '000103f0d9cfb60f',\n",
       "  '008a990457283850',\n",
       "  '00290e2a171dd073',\n",
       "  '006493e4e9c89cab',\n",
       "  '0060ef190ee10720',\n",
       "  '0034d7c78cfa6dee',\n",
       "  '0048e4ed8a0af433',\n",
       "  '007094f2f9efe035',\n",
       "  '006b94add72ed61c',\n",
       "  '0097b052f0b68a96',\n",
       "  '006fc8cfaa4faf0b',\n",
       "  '0050cb3bc226f94e',\n",
       "  '0010307a3a50a353',\n",
       "  '00686325bcc16080',\n",
       "  '00a216c00b90ce88',\n",
       "  '004a23742282fee4',\n",
       "  '00169857adbc989b',\n",
       "  '001e89eb3f0b0915',\n",
       "  '008a856f6691e051',\n",
       "  '004fb9f655230909',\n",
       "  '0053978373606ba4',\n",
       "  '009371b0ef213487',\n",
       "  '003d77a20601cec1',\n",
       "  '002918ae66cc4bc2',\n",
       "  '0073059e6433db47',\n",
       "  '006b77d41eb4bc08',\n",
       "  '009a52daa8dbb767',\n",
       "  '004fd4fb5c47c29f',\n",
       "  '0066dcf7d9ecd360',\n",
       "  '0090c1f0788dd0e9',\n",
       "  '00548d029d7f4783',\n",
       "  '00316bcc0d1bc6e0',\n",
       "  '0029541a38c523a0',\n",
       "  '006fda507acd9769',\n",
       "  '0055208c660f7894',\n",
       "  '009a6b3e571ee155'],\n",
       " 'label': tensor([[0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 1., 0., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 0., 1., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 1., 0., 0., 0.],\n",
       "         [1., 0., 1., 0., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 1., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 1., 0., 1., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.]])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[259,  73, 112,  ..., 261, 261, 261],\n",
       "         [259, 100,  98,  ..., 261, 261, 261],\n",
       "         [259, 112, 111,  ..., 261, 261, 261],\n",
       "         ...,\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
       "\n",
       "        [[259, 118, 260,  ..., 261, 261, 261],\n",
       "         [259, 115, 260,  ..., 261, 261, 261],\n",
       "         [259,  98, 260,  ..., 261, 261, 261],\n",
       "         ...,\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
       "\n",
       "        [[259,  74, 260,  ..., 261, 261, 261],\n",
       "         [259,  71,  74,  ..., 261, 261, 261],\n",
       "         [259,  74,  85,  ..., 261, 261, 261],\n",
       "         ...,\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[259,  35, 260,  ..., 261, 261, 261],\n",
       "         [259,  81, 109,  ..., 261, 261, 261],\n",
       "         [259, 101, 112,  ..., 261, 261, 261],\n",
       "         ...,\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
       "\n",
       "        [[259,  85, 105,  ..., 261, 261, 261],\n",
       "         [259, 117, 105,  ..., 261, 261, 261],\n",
       "         [259, 106, 116,  ..., 261, 261, 261],\n",
       "         ...,\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
       "\n",
       "        [[259, 110, 112,  ..., 261, 261, 261],\n",
       "         [259, 106, 111,  ..., 261, 261, 261],\n",
       "         [259,  85, 105,  ..., 261, 261, 261],\n",
       "         ...,\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"tokens\"][\"tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 44, 50])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"tokens\"][\"tokens\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.modules.seq2vec_encoders import Seq2VecEncoder, PytorchSeq2VecWrapper\n",
    "from allennlp.nn.util import get_text_field_mask\n",
    "from allennlp.models import Model\n",
    "from allennlp.modules.text_field_embedders import TextFieldEmbedder\n",
    "\n",
    "class BaselineModel(Model):\n",
    "    def __init__(self, word_embeddings: TextFieldEmbedder,\n",
    "                 encoder: Seq2VecEncoder,\n",
    "                 out_sz: int=len(label_cols)):\n",
    "        super().__init__(vocab)\n",
    "        self.word_embeddings = word_embeddings\n",
    "        self.encoder = encoder\n",
    "        self.projection = nn.Linear(self.encoder.get_output_dim(), out_sz)\n",
    "        self.loss = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "    def forward(self, tokens: Dict[str, torch.Tensor],\n",
    "                id: Any, label: torch.Tensor) -> torch.Tensor:\n",
    "        mask = get_text_field_mask(tokens)\n",
    "        embeddings = self.word_embeddings(tokens)\n",
    "        state = self.encoder(embeddings, mask)\n",
    "        class_logits = self.projection(state)\n",
    "        \n",
    "        output = {\"class_logits\": class_logits}\n",
    "        output[\"loss\"] = self.loss(class_logits, label)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 336/336 [00:00<00:00, 66497.72B/s]\n",
      "100%|██████████| 54402456/54402456 [00:15<00:00, 3448186.09B/s]\n"
     ]
    }
   ],
   "source": [
    "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders import ElmoTokenEmbedder\n",
    "\n",
    "options_file = 'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_options.json'\n",
    "weight_file = 'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'\n",
    "\n",
    "elmo_embedder = ElmoTokenEmbedder(options_file, weight_file)\n",
    "word_embeddings = BasicTextFieldEmbedder({\"tokens\": elmo_embedder})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.modules.seq2vec_encoders import PytorchSeq2VecWrapper\n",
    "encoder: Seq2VecEncoder = PytorchSeq2VecWrapper(nn.LSTM(word_embeddings.get_output_dim(), config.hidden_sz, bidirectional=True, batch_first=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how simple and modular the code for initializing the model is. All the complexity is delegated to each component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaselineModel(\n",
    "    word_embeddings, \n",
    "    encoder, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_GPU: model.cuda()\n",
    "else: model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = nn_util.move_to_device(batch, 0 if USE_GPU else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = batch[\"tokens\"]\n",
    "labels = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': tensor([[[259,  73, 112,  ..., 261, 261, 261],\n",
       "          [259, 100,  98,  ..., 261, 261, 261],\n",
       "          [259, 112, 111,  ..., 261, 261, 261],\n",
       "          ...,\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "         [[259, 118, 260,  ..., 261, 261, 261],\n",
       "          [259, 115, 260,  ..., 261, 261, 261],\n",
       "          [259,  98, 260,  ..., 261, 261, 261],\n",
       "          ...,\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "         [[259,  74, 260,  ..., 261, 261, 261],\n",
       "          [259,  71,  74,  ..., 261, 261, 261],\n",
       "          [259,  74,  85,  ..., 261, 261, 261],\n",
       "          ...,\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[259,  35, 260,  ..., 261, 261, 261],\n",
       "          [259,  81, 109,  ..., 261, 261, 261],\n",
       "          [259, 101, 112,  ..., 261, 261, 261],\n",
       "          ...,\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "         [[259,  85, 105,  ..., 261, 261, 261],\n",
       "          [259, 117, 105,  ..., 261, 261, 261],\n",
       "          [259, 106, 116,  ..., 261, 261, 261],\n",
       "          ...,\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "         [[259, 110, 112,  ..., 261, 261, 261],\n",
       "          [259, 106, 111,  ..., 261, 261, 261],\n",
       "          [259,  85, 105,  ..., 261, 261, 261],\n",
       "          ...,\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0]]])}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = get_text_field_mask(tokens)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0529, -0.0262,  0.0334,  0.0932,  0.0485, -0.1344],\n",
       "        [-0.2047,  0.1432,  0.2211, -0.0746, -0.0116, -0.1761],\n",
       "        [ 0.1327,  0.1339,  0.0710, -0.0759,  0.0915, -0.1714],\n",
       "        [-0.1824,  0.0264, -0.0531, -0.0794, -0.0975, -0.0400],\n",
       "        [ 0.1211, -0.0398,  0.1096, -0.0567,  0.0396, -0.1569],\n",
       "        [ 0.1192, -0.0919, -0.0552, -0.1347,  0.0565, -0.2150],\n",
       "        [-0.0318, -0.0296, -0.0416, -0.0455,  0.1911, -0.0015],\n",
       "        [ 0.0815,  0.1096,  0.1019, -0.0069, -0.0878, -0.1423],\n",
       "        [-0.0638,  0.0486,  0.0728, -0.0058,  0.1464, -0.0970],\n",
       "        [-0.0033,  0.0701,  0.1995, -0.0891, -0.0786, -0.1392],\n",
       "        [ 0.0557,  0.0172,  0.1095,  0.0373,  0.1495, -0.0161],\n",
       "        [ 0.0774, -0.1143,  0.0411, -0.0092,  0.1410, -0.1466],\n",
       "        [-0.0185, -0.0398,  0.0511,  0.0097,  0.1832, -0.0019],\n",
       "        [ 0.0347, -0.0351,  0.1361, -0.0501,  0.0505, -0.1964],\n",
       "        [ 0.0262,  0.0115, -0.0532,  0.0221,  0.1430,  0.0151],\n",
       "        [ 0.0248,  0.0891,  0.1217,  0.0885,  0.0045, -0.0459],\n",
       "        [-0.1020, -0.1225,  0.2962,  0.1998, -0.0742, -0.1198],\n",
       "        [-0.1111,  0.0333, -0.0090,  0.0282,  0.0475, -0.1337],\n",
       "        [ 0.1036, -0.0735, -0.0211,  0.0175,  0.0641, -0.1505],\n",
       "        [-0.0360,  0.0097,  0.1441, -0.0427,  0.0989, -0.1761],\n",
       "        [-0.0418, -0.0164,  0.0055,  0.1015,  0.0316, -0.1847],\n",
       "        [ 0.1706,  0.0194,  0.2600, -0.1016,  0.1806,  0.0805],\n",
       "        [ 0.0043, -0.0169, -0.0379, -0.0571, -0.0849, -0.0170],\n",
       "        [ 0.1930,  0.0621,  0.0210, -0.0849,  0.1716, -0.0769],\n",
       "        [-0.1021,  0.2056,  0.1178, -0.0639, -0.0619,  0.0112],\n",
       "        [ 0.0104, -0.0827,  0.0754,  0.0027, -0.0552, -0.0887],\n",
       "        [-0.0015,  0.0645,  0.0731, -0.0425,  0.1854, -0.1155],\n",
       "        [-0.1006,  0.1985, -0.0607,  0.0197,  0.0955, -0.1365],\n",
       "        [ 0.1168,  0.2587,  0.2722,  0.1299,  0.0515, -0.2392],\n",
       "        [-0.1121, -0.0466, -0.0826, -0.0437,  0.0332, -0.1476],\n",
       "        [ 0.1019,  0.1663,  0.1143, -0.1895, -0.0029, -0.2090],\n",
       "        [-0.1401,  0.0409,  0.1082,  0.0143,  0.2669, -0.2578],\n",
       "        [-0.1055,  0.0265,  0.1052,  0.0998, -0.0332, -0.1766],\n",
       "        [-0.0591, -0.0584,  0.0116,  0.0822,  0.0891, -0.0623],\n",
       "        [-0.0153,  0.0286,  0.1331,  0.0412,  0.0719, -0.2739],\n",
       "        [-0.0169, -0.1274, -0.1569, -0.1442, -0.0647, -0.0863],\n",
       "        [-0.0105,  0.0456,  0.0614,  0.0663, -0.0397, -0.2033],\n",
       "        [ 0.1120, -0.0323,  0.1856, -0.0532,  0.0675, -0.3286],\n",
       "        [-0.0077,  0.3179,  0.0543,  0.0891,  0.1470, -0.1309],\n",
       "        [-0.0153, -0.1864, -0.0665, -0.0408,  0.0935, -0.0237],\n",
       "        [ 0.1157,  0.1077,  0.2506,  0.0299,  0.0967, -0.2674],\n",
       "        [ 0.0457, -0.1072, -0.0404, -0.1038, -0.0697, -0.0844],\n",
       "        [ 0.0243, -0.1392, -0.1057,  0.1640,  0.1290, -0.0517],\n",
       "        [-0.0848,  0.0120,  0.0169,  0.0431, -0.0289, -0.0793],\n",
       "        [ 0.0136,  0.0535,  0.0631, -0.1005,  0.0889, -0.0670],\n",
       "        [-0.2748,  0.2435,  0.1544, -0.0365, -0.0033, -0.3372],\n",
       "        [-0.1564,  0.0678,  0.0698,  0.1084,  0.1654, -0.2303],\n",
       "        [-0.0128, -0.0246,  0.0337,  0.0496,  0.2222, -0.2751],\n",
       "        [ 0.0576, -0.0068,  0.2223,  0.0464,  0.1027, -0.1645],\n",
       "        [-0.0330, -0.0461, -0.1010,  0.0415,  0.1831, -0.0519],\n",
       "        [ 0.0743,  0.1130,  0.0163,  0.0485,  0.1187, -0.0669],\n",
       "        [-0.0102,  0.0973,  0.1412, -0.0028,  0.0813, -0.0674],\n",
       "        [-0.0045, -0.0733,  0.0250,  0.1161,  0.0360, -0.0175],\n",
       "        [ 0.0801, -0.0290,  0.1694,  0.0369,  0.0787, -0.1452],\n",
       "        [-0.1017,  0.1398,  0.1826, -0.1863,  0.0368,  0.0696],\n",
       "        [ 0.0138,  0.1513,  0.2261,  0.0676, -0.0120, -0.0711],\n",
       "        [-0.0747,  0.0955,  0.0720, -0.0301,  0.0388, -0.0786],\n",
       "        [-0.0263,  0.0805,  0.2329,  0.0212,  0.0233, -0.1804],\n",
       "        [ 0.0724, -0.0259,  0.1044, -0.1496,  0.2429, -0.2281],\n",
       "        [-0.1911, -0.0183,  0.1342, -0.0416, -0.0150, -0.1196],\n",
       "        [ 0.0357,  0.0014,  0.1026,  0.0105,  0.0111, -0.0819],\n",
       "        [-0.1051,  0.0637, -0.0244, -0.1739,  0.0503, -0.1312],\n",
       "        [-0.1056,  0.0144, -0.0312,  0.0083,  0.0145, -0.1339],\n",
       "        [ 0.0042,  0.0798,  0.2334, -0.1892,  0.0393, -0.1162]],\n",
       "       grad_fn=<ThAddmmBackward>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = model.word_embeddings(tokens)\n",
    "state = model.encoder(embeddings, mask)\n",
    "class_logits = model.projection(state)\n",
    "class_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_logits': tensor([[-0.0789, -0.1261, -0.0641,  0.2692,  0.0014, -0.1165],\n",
       "         [-0.0858, -0.0294,  0.2109, -0.1133,  0.1685, -0.1553],\n",
       "         [ 0.0456, -0.0177, -0.0270, -0.0888,  0.1982, -0.3067],\n",
       "         [-0.2441,  0.1275, -0.0710,  0.0294, -0.1422,  0.0463],\n",
       "         [ 0.0972,  0.1346,  0.0665, -0.1366, -0.0044, -0.1929],\n",
       "         [ 0.0320,  0.0629,  0.1336, -0.1517,  0.0499, -0.1969],\n",
       "         [-0.1300,  0.0034, -0.0815, -0.0457,  0.0362, -0.1183],\n",
       "         [ 0.0479,  0.0893,  0.1817, -0.0265,  0.0573, -0.1004],\n",
       "         [ 0.0051, -0.0023,  0.0390,  0.0055,  0.0821,  0.0788],\n",
       "         [ 0.0413,  0.1456,  0.2980,  0.1062, -0.1394, -0.1347],\n",
       "         [-0.0863,  0.0092,  0.1713,  0.1499,  0.0142,  0.0188],\n",
       "         [ 0.0976,  0.0484,  0.1318, -0.0328,  0.1388, -0.2082],\n",
       "         [-0.0710, -0.0588,  0.1363, -0.0134,  0.1604, -0.2077],\n",
       "         [-0.1084, -0.0315,  0.1354,  0.0544,  0.2159, -0.2088],\n",
       "         [ 0.1554, -0.0027, -0.0675,  0.0137,  0.1493, -0.0789],\n",
       "         [ 0.0053,  0.0715,  0.1071, -0.0563, -0.0456, -0.1633],\n",
       "         [-0.0622,  0.0039,  0.1544,  0.0719,  0.0168, -0.0212],\n",
       "         [-0.0482, -0.0420,  0.1032,  0.0418,  0.1577, -0.2556],\n",
       "         [ 0.1039, -0.0837,  0.0112,  0.0666, -0.0796, -0.0322],\n",
       "         [ 0.0635,  0.1358,  0.0649,  0.0045,  0.0767, -0.0365],\n",
       "         [-0.0156, -0.0440,  0.1667,  0.0767,  0.2737, -0.2033],\n",
       "         [-0.0844,  0.0374, -0.0011,  0.0194, -0.0627, -0.0327],\n",
       "         [-0.0948, -0.0282,  0.0872, -0.0440,  0.0902, -0.1397],\n",
       "         [ 0.1640,  0.0625,  0.1192,  0.0946,  0.0364, -0.2747],\n",
       "         [-0.1045,  0.0008, -0.0422, -0.1382, -0.0350, -0.0397],\n",
       "         [-0.0039, -0.0615,  0.1164,  0.1473,  0.0783, -0.1985],\n",
       "         [-0.0102,  0.1668, -0.0914, -0.0293,  0.0735, -0.2547],\n",
       "         [-0.0779, -0.1065,  0.1138, -0.0854,  0.2543, -0.0899],\n",
       "         [ 0.1111, -0.0109, -0.0286, -0.0008,  0.0442, -0.1352],\n",
       "         [-0.1105, -0.0166, -0.0300, -0.0465,  0.2419, -0.0698],\n",
       "         [ 0.0182,  0.0143,  0.1377,  0.0001, -0.1217, -0.0108],\n",
       "         [-0.0743,  0.0743,  0.0255, -0.0950,  0.1640, -0.0624],\n",
       "         [-0.0128, -0.1494,  0.0137, -0.0094,  0.0524, -0.2470],\n",
       "         [ 0.0427, -0.1933,  0.1207, -0.0911, -0.0033,  0.0491],\n",
       "         [ 0.1536, -0.0694, -0.0654, -0.1146,  0.0573, -0.1894],\n",
       "         [-0.1038, -0.1107,  0.0813,  0.0428,  0.1019, -0.0196],\n",
       "         [-0.0027,  0.0351,  0.0846,  0.1429,  0.0033, -0.0557],\n",
       "         [-0.0116, -0.0228, -0.0684, -0.0375,  0.0173, -0.2815],\n",
       "         [-0.1357,  0.0436, -0.0233,  0.1127,  0.0274, -0.0442],\n",
       "         [ 0.0554, -0.0257,  0.1778,  0.0014,  0.2477, -0.1037],\n",
       "         [ 0.1013, -0.0162,  0.1395,  0.0892, -0.0399, -0.0444],\n",
       "         [-0.1550, -0.0811,  0.0057, -0.1293, -0.0785, -0.1691],\n",
       "         [ 0.0074, -0.0931, -0.0296, -0.0305,  0.0645, -0.0711],\n",
       "         [ 0.0606,  0.0405,  0.1368, -0.0428, -0.0925, -0.0540],\n",
       "         [-0.1380,  0.0246,  0.0181, -0.0228,  0.0154,  0.0787],\n",
       "         [-0.1625, -0.0409,  0.0074,  0.1664,  0.0953, -0.3179],\n",
       "         [-0.1914,  0.0540,  0.1614,  0.0028, -0.0659, -0.0808],\n",
       "         [ 0.0292,  0.0670,  0.1573,  0.0335,  0.0503, -0.2579],\n",
       "         [ 0.1053, -0.0295,  0.0853, -0.2316,  0.2689, -0.1291],\n",
       "         [-0.0366, -0.0953, -0.0013,  0.1080,  0.0482, -0.1664],\n",
       "         [ 0.1119,  0.2431,  0.0614, -0.0279, -0.0941,  0.0022],\n",
       "         [ 0.1133, -0.0361,  0.0324,  0.1878, -0.0262, -0.0056],\n",
       "         [-0.0292, -0.0027,  0.0706,  0.1469,  0.0505, -0.0328],\n",
       "         [ 0.0402,  0.0096,  0.2115,  0.0422,  0.1427, -0.1056],\n",
       "         [-0.0170, -0.1419,  0.2314, -0.0688,  0.0693,  0.0289],\n",
       "         [ 0.1184,  0.1558,  0.1953,  0.0976,  0.0533, -0.1647],\n",
       "         [-0.0768,  0.0703,  0.1816,  0.0202,  0.0834,  0.0088],\n",
       "         [ 0.1246, -0.0173,  0.1605, -0.0146, -0.0440, -0.2115],\n",
       "         [-0.0246, -0.0274,  0.0552, -0.0909,  0.1833, -0.0685],\n",
       "         [-0.0116, -0.0063, -0.0206,  0.0449, -0.0010, -0.1089],\n",
       "         [-0.0566,  0.0623, -0.1125,  0.0378,  0.0469, -0.0440],\n",
       "         [ 0.0879,  0.0139,  0.0570, -0.0435,  0.1405, -0.1314],\n",
       "         [ 0.0929,  0.0138,  0.0051,  0.0216, -0.0280, -0.0483],\n",
       "         [-0.2219, -0.0079, -0.0751,  0.0721,  0.0290, -0.1333]],\n",
       "        grad_fn=<ThAddmmBackward>),\n",
       " 'loss': tensor(0.6963, grad_fn=<MeanBackward1>)}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model(**batch)[\"loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6976, grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-9.9208e-06,  9.9129e-05,  5.0682e-05,  ..., -8.7041e-05,\n",
       "           3.5600e-05,  7.6566e-06],\n",
       "         [-1.1369e-04, -5.1152e-05, -7.5502e-05,  ..., -1.1979e-04,\n",
       "           1.2605e-04, -1.8761e-05],\n",
       "         [-1.3619e-04,  1.0717e-04,  2.7693e-05,  ...,  5.1606e-05,\n",
       "           2.1356e-04,  4.0541e-05],\n",
       "         ...,\n",
       "         [ 1.8521e-04,  1.4536e-05,  3.9201e-05,  ...,  1.8680e-05,\n",
       "          -2.3767e-04,  1.4379e-05],\n",
       "         [ 7.9033e-05,  1.5386e-05,  2.5557e-05,  ..., -6.1518e-05,\n",
       "          -7.9275e-05, -1.4077e-05],\n",
       "         [ 1.7141e-04, -4.5310e-07,  5.8982e-05,  ..., -1.1607e-04,\n",
       "          -2.5490e-04,  8.1655e-05]]),\n",
       " tensor([[ 1.5749e-05,  8.9245e-06, -1.5019e-05,  ..., -5.9032e-06,\n",
       "          -4.1844e-08, -1.0729e-05],\n",
       "         [-2.6297e-05, -5.4704e-07, -4.8005e-05,  ..., -3.4190e-05,\n",
       "          -4.1296e-05, -5.2007e-06],\n",
       "         [ 5.1598e-05, -8.1258e-06, -8.2521e-05,  ..., -2.8385e-05,\n",
       "           2.3811e-05,  4.0387e-05],\n",
       "         ...,\n",
       "         [ 3.0995e-05,  5.1719e-05,  1.2696e-04,  ...,  8.6867e-05,\n",
       "          -2.9523e-05, -8.7645e-05],\n",
       "         [-5.1864e-06,  3.5313e-05,  2.5837e-05,  ...,  1.7943e-05,\n",
       "          -7.5555e-05, -3.1711e-05],\n",
       "         [-3.0279e-05,  4.6222e-05,  1.4948e-04,  ..., -1.7436e-05,\n",
       "          -3.9489e-05, -1.2987e-04]]),\n",
       " tensor([-1.7675e-05, -1.9221e-04, -4.4385e-04, -8.7884e-05,  8.2569e-05,\n",
       "         -7.7098e-05,  2.6371e-04,  8.5955e-05,  7.3837e-05, -1.6548e-05,\n",
       "          4.3878e-04,  7.5250e-04,  1.6888e-04, -2.8592e-04,  2.7507e-04,\n",
       "         -3.9196e-04,  1.4837e-05,  1.1284e-04,  5.0613e-04, -6.5626e-05,\n",
       "         -6.1392e-05, -6.1163e-05, -1.6846e-04, -1.7342e-04, -5.0795e-05,\n",
       "          1.0901e-04, -2.8735e-04, -6.5975e-04,  1.7789e-04,  2.8461e-04,\n",
       "         -2.9404e-04,  2.5080e-04, -1.0801e-04,  1.5974e-04, -1.6760e-05,\n",
       "          1.0417e-04, -3.8597e-04,  1.1910e-04,  4.4532e-05,  1.6219e-06,\n",
       "         -2.4597e-04, -2.5003e-05, -1.4339e-04, -1.8059e-04, -2.0973e-05,\n",
       "          8.0034e-05,  1.4814e-04, -1.4978e-05, -9.3981e-04,  4.4181e-05,\n",
       "          2.7056e-04, -1.9163e-05,  2.4713e-04, -2.9818e-04,  1.0818e-04,\n",
       "          4.8831e-04, -1.6867e-04,  2.5835e-04,  2.3463e-04, -3.4553e-05,\n",
       "         -9.1519e-05,  4.6341e-04,  1.0164e-04,  5.6417e-04, -1.5907e-04,\n",
       "          6.0696e-05, -3.5159e-04, -5.2042e-05,  4.6557e-04, -2.2335e-04,\n",
       "          2.3010e-06,  1.2923e-04,  4.0576e-04,  2.1470e-04,  3.4290e-04,\n",
       "          3.7652e-04, -4.0085e-04, -1.2561e-03,  5.0848e-04, -3.4840e-04,\n",
       "          5.0710e-05,  2.7879e-04,  4.7544e-04, -6.8201e-05,  4.5729e-05,\n",
       "         -1.1417e-04,  1.8958e-04, -2.0925e-04, -6.6401e-05, -2.0518e-04,\n",
       "         -2.1331e-04, -5.1714e-04,  1.2973e-04,  1.3288e-04, -2.1217e-04,\n",
       "          1.9674e-04, -2.5616e-04,  2.3135e-04,  4.5417e-05,  3.4110e-05,\n",
       "         -3.7183e-04,  1.1200e-04,  3.0737e-04,  3.9875e-05, -4.7834e-04,\n",
       "          7.8242e-06, -1.7986e-04, -2.5821e-04,  1.2527e-04,  7.1665e-05,\n",
       "          9.3186e-05,  1.4630e-05, -6.9726e-04,  3.0842e-05,  1.4855e-04,\n",
       "          1.2152e-05,  2.1644e-04, -2.7628e-04,  9.3653e-05,  6.2729e-04,\n",
       "         -8.5030e-05,  3.4885e-05,  1.5254e-04, -1.2129e-04, -2.9314e-06,\n",
       "          5.4785e-05, -2.6685e-06,  5.6553e-04,  3.3283e-03,  3.9468e-03,\n",
       "         -1.0852e-03,  3.2296e-04, -3.7035e-03,  2.4856e-03, -5.7872e-03,\n",
       "         -1.1218e-03,  4.4556e-03, -2.5033e-03, -3.5504e-03, -4.3952e-03,\n",
       "         -8.5215e-03, -3.8819e-03, -7.7824e-03,  3.5840e-03, -4.9808e-05,\n",
       "          8.7743e-04, -2.3684e-03,  5.8847e-03, -2.2434e-03, -2.8801e-03,\n",
       "          5.7569e-03,  3.1299e-03, -2.3158e-04, -4.9742e-03,  3.6959e-03,\n",
       "         -4.8239e-03, -9.5858e-04, -1.5972e-03,  1.7541e-03, -1.2832e-03,\n",
       "          1.8568e-03,  1.3832e-03,  1.9051e-03, -5.5138e-04, -2.3410e-03,\n",
       "          6.9077e-04, -1.9112e-03, -1.3262e-03,  3.3342e-03, -2.6816e-03,\n",
       "          2.3059e-04,  1.3351e-03,  2.6201e-03, -6.4872e-04, -1.7455e-04,\n",
       "          1.2749e-04, -3.2261e-03,  2.1809e-04, -2.5961e-03, -8.4376e-04,\n",
       "         -2.4834e-03,  4.5479e-03,  9.0311e-04,  1.4792e-03,  1.4324e-03,\n",
       "          3.4706e-03,  7.1890e-04,  1.4356e-03,  1.4640e-03,  2.3010e-03,\n",
       "         -1.5289e-03, -3.7271e-03, -1.4530e-04, -2.4424e-04, -4.5547e-04,\n",
       "         -7.6861e-05, -1.2022e-05,  5.8224e-07,  2.6214e-04,  1.0979e-04,\n",
       "          4.4623e-05, -5.6888e-05,  4.3125e-04,  4.8128e-04,  1.3364e-05,\n",
       "         -4.1183e-04,  3.7018e-04, -6.7797e-04,  1.0723e-05,  2.2363e-04,\n",
       "          7.3448e-04, -2.0034e-04, -9.8451e-05,  3.9107e-06, -1.8269e-04,\n",
       "         -3.4798e-04, -7.0379e-05,  2.8207e-05, -3.1217e-04, -7.8403e-04,\n",
       "          2.2394e-04,  3.1423e-04, -2.4336e-04,  2.5533e-04, -1.5588e-04,\n",
       "          2.4931e-04, -1.4106e-04,  1.7313e-04, -6.2664e-04,  8.1834e-05,\n",
       "          8.3460e-05, -2.1557e-05, -3.1880e-04, -4.1305e-05, -1.7514e-04,\n",
       "         -2.9511e-04, -7.5691e-05,  5.4077e-05,  1.1967e-04, -1.1363e-05,\n",
       "         -1.6238e-03,  6.6282e-05,  4.3715e-04, -5.0629e-05,  4.8482e-04,\n",
       "         -4.3815e-04,  1.2713e-04,  8.4604e-04, -1.5531e-04,  3.3376e-04,\n",
       "          2.3284e-04, -8.9566e-05, -7.5954e-05,  7.8142e-04,  1.1216e-04,\n",
       "          7.1141e-04]),\n",
       " tensor([-1.7675e-05, -1.9221e-04, -4.4385e-04, -8.7884e-05,  8.2569e-05,\n",
       "         -7.7098e-05,  2.6371e-04,  8.5955e-05,  7.3837e-05, -1.6548e-05,\n",
       "          4.3878e-04,  7.5250e-04,  1.6888e-04, -2.8592e-04,  2.7507e-04,\n",
       "         -3.9196e-04,  1.4837e-05,  1.1284e-04,  5.0613e-04, -6.5626e-05,\n",
       "         -6.1392e-05, -6.1163e-05, -1.6846e-04, -1.7342e-04, -5.0795e-05,\n",
       "          1.0901e-04, -2.8735e-04, -6.5975e-04,  1.7789e-04,  2.8461e-04,\n",
       "         -2.9404e-04,  2.5080e-04, -1.0801e-04,  1.5974e-04, -1.6760e-05,\n",
       "          1.0417e-04, -3.8597e-04,  1.1910e-04,  4.4532e-05,  1.6219e-06,\n",
       "         -2.4597e-04, -2.5003e-05, -1.4339e-04, -1.8059e-04, -2.0973e-05,\n",
       "          8.0034e-05,  1.4814e-04, -1.4978e-05, -9.3981e-04,  4.4181e-05,\n",
       "          2.7056e-04, -1.9163e-05,  2.4713e-04, -2.9818e-04,  1.0818e-04,\n",
       "          4.8831e-04, -1.6867e-04,  2.5835e-04,  2.3463e-04, -3.4553e-05,\n",
       "         -9.1519e-05,  4.6341e-04,  1.0164e-04,  5.6417e-04, -1.5907e-04,\n",
       "          6.0696e-05, -3.5159e-04, -5.2042e-05,  4.6557e-04, -2.2335e-04,\n",
       "          2.3010e-06,  1.2923e-04,  4.0576e-04,  2.1470e-04,  3.4290e-04,\n",
       "          3.7652e-04, -4.0085e-04, -1.2561e-03,  5.0848e-04, -3.4840e-04,\n",
       "          5.0710e-05,  2.7879e-04,  4.7544e-04, -6.8201e-05,  4.5729e-05,\n",
       "         -1.1417e-04,  1.8958e-04, -2.0925e-04, -6.6401e-05, -2.0518e-04,\n",
       "         -2.1331e-04, -5.1714e-04,  1.2973e-04,  1.3288e-04, -2.1217e-04,\n",
       "          1.9674e-04, -2.5616e-04,  2.3135e-04,  4.5417e-05,  3.4110e-05,\n",
       "         -3.7183e-04,  1.1200e-04,  3.0737e-04,  3.9875e-05, -4.7834e-04,\n",
       "          7.8242e-06, -1.7986e-04, -2.5821e-04,  1.2527e-04,  7.1665e-05,\n",
       "          9.3186e-05,  1.4630e-05, -6.9726e-04,  3.0842e-05,  1.4855e-04,\n",
       "          1.2152e-05,  2.1644e-04, -2.7628e-04,  9.3653e-05,  6.2729e-04,\n",
       "         -8.5030e-05,  3.4885e-05,  1.5254e-04, -1.2129e-04, -2.9314e-06,\n",
       "          5.4785e-05, -2.6685e-06,  5.6553e-04,  3.3283e-03,  3.9468e-03,\n",
       "         -1.0852e-03,  3.2296e-04, -3.7035e-03,  2.4856e-03, -5.7872e-03,\n",
       "         -1.1218e-03,  4.4556e-03, -2.5033e-03, -3.5504e-03, -4.3952e-03,\n",
       "         -8.5215e-03, -3.8819e-03, -7.7824e-03,  3.5840e-03, -4.9808e-05,\n",
       "          8.7743e-04, -2.3684e-03,  5.8847e-03, -2.2434e-03, -2.8801e-03,\n",
       "          5.7569e-03,  3.1299e-03, -2.3158e-04, -4.9742e-03,  3.6959e-03,\n",
       "         -4.8239e-03, -9.5858e-04, -1.5972e-03,  1.7541e-03, -1.2832e-03,\n",
       "          1.8568e-03,  1.3832e-03,  1.9051e-03, -5.5138e-04, -2.3410e-03,\n",
       "          6.9077e-04, -1.9112e-03, -1.3262e-03,  3.3342e-03, -2.6816e-03,\n",
       "          2.3059e-04,  1.3351e-03,  2.6201e-03, -6.4872e-04, -1.7455e-04,\n",
       "          1.2749e-04, -3.2261e-03,  2.1809e-04, -2.5961e-03, -8.4376e-04,\n",
       "         -2.4834e-03,  4.5479e-03,  9.0311e-04,  1.4792e-03,  1.4324e-03,\n",
       "          3.4706e-03,  7.1890e-04,  1.4356e-03,  1.4640e-03,  2.3010e-03,\n",
       "         -1.5289e-03, -3.7271e-03, -1.4530e-04, -2.4424e-04, -4.5547e-04,\n",
       "         -7.6861e-05, -1.2022e-05,  5.8224e-07,  2.6214e-04,  1.0979e-04,\n",
       "          4.4623e-05, -5.6888e-05,  4.3125e-04,  4.8128e-04,  1.3364e-05,\n",
       "         -4.1183e-04,  3.7018e-04, -6.7797e-04,  1.0723e-05,  2.2363e-04,\n",
       "          7.3448e-04, -2.0034e-04, -9.8451e-05,  3.9107e-06, -1.8269e-04,\n",
       "         -3.4798e-04, -7.0379e-05,  2.8207e-05, -3.1217e-04, -7.8403e-04,\n",
       "          2.2394e-04,  3.1423e-04, -2.4336e-04,  2.5533e-04, -1.5588e-04,\n",
       "          2.4931e-04, -1.4106e-04,  1.7313e-04, -6.2664e-04,  8.1834e-05,\n",
       "          8.3460e-05, -2.1557e-05, -3.1880e-04, -4.1305e-05, -1.7514e-04,\n",
       "         -2.9511e-04, -7.5691e-05,  5.4077e-05,  1.1967e-04, -1.1363e-05,\n",
       "         -1.6238e-03,  6.6282e-05,  4.3715e-04, -5.0629e-05,  4.8482e-04,\n",
       "         -4.3815e-04,  1.2713e-04,  8.4604e-04, -1.5531e-04,  3.3376e-04,\n",
       "          2.3284e-04, -8.9566e-05, -7.5954e-05,  7.8142e-04,  1.1216e-04,\n",
       "          7.1141e-04]),\n",
       " tensor([[-1.8399e-05,  7.0910e-06,  9.1924e-06,  ...,  3.7554e-05,\n",
       "          -2.4166e-05, -1.0245e-04],\n",
       "         [ 6.6780e-06,  4.9700e-05,  3.2534e-05,  ..., -3.1291e-05,\n",
       "           8.4457e-06, -4.8003e-05],\n",
       "         [-5.4695e-05,  3.4727e-05,  9.3938e-05,  ..., -6.8500e-05,\n",
       "           8.2833e-06,  1.2045e-04],\n",
       "         ...,\n",
       "         [ 1.0635e-04,  8.4368e-06, -6.7792e-05,  ..., -8.6073e-05,\n",
       "          -1.2397e-04, -4.3281e-06],\n",
       "         [-1.6445e-05,  5.6125e-05,  4.4340e-06,  ..., -3.0222e-05,\n",
       "          -5.7461e-06,  4.3694e-05],\n",
       "         [ 8.1800e-05,  2.7373e-04,  1.4603e-04,  ..., -1.7179e-04,\n",
       "          -8.9895e-05,  4.4834e-04]]),\n",
       " tensor([[ 1.4014e-05,  2.1556e-05,  2.0991e-06,  ..., -1.6088e-05,\n",
       "          -7.2318e-06,  2.3356e-05],\n",
       "         [ 2.3855e-05,  8.4428e-06,  1.0799e-05,  ..., -1.5987e-06,\n",
       "          -3.0069e-06,  9.7224e-07],\n",
       "         [ 1.4505e-05, -1.7964e-06, -2.0693e-06,  ..., -1.8148e-05,\n",
       "          -1.5402e-05, -1.6551e-05],\n",
       "         ...,\n",
       "         [ 8.8416e-06, -1.2211e-05, -2.3169e-05,  ...,  4.4728e-05,\n",
       "          -8.6539e-06,  5.4907e-05],\n",
       "         [ 5.0068e-06, -2.0755e-08, -1.2655e-06,  ...,  6.7794e-07,\n",
       "           1.6495e-06,  1.4817e-05],\n",
       "         [ 2.8418e-05, -6.6855e-06, -1.0862e-05,  ...,  2.1186e-05,\n",
       "          -2.9821e-05,  1.4481e-04]]),\n",
       " tensor([-1.2702e-04, -6.0000e-05, -4.9699e-05,  1.4435e-04,  3.7387e-04,\n",
       "          3.2760e-05, -2.2994e-05,  5.1977e-05,  2.3162e-05, -8.3897e-07,\n",
       "          9.6787e-05, -4.0692e-04, -1.2392e-04, -5.3713e-04,  5.1452e-04,\n",
       "         -1.0483e-04,  1.2323e-04,  4.4483e-05, -2.2620e-04, -1.4437e-04,\n",
       "          1.3898e-04,  7.3699e-06, -1.6570e-04, -1.1200e-04, -1.0253e-04,\n",
       "         -8.6140e-05, -7.6131e-05, -1.7618e-04, -1.0142e-04,  1.9683e-04,\n",
       "          1.9060e-04, -7.5373e-05, -6.2845e-05, -4.8453e-05,  2.2551e-04,\n",
       "          1.4130e-04,  1.2706e-04, -1.2890e-04,  1.0814e-03,  6.2642e-05,\n",
       "          2.7289e-04, -4.9046e-04, -3.8368e-04, -1.1005e-04, -9.4567e-05,\n",
       "         -4.7188e-06,  7.5073e-04, -7.2997e-04, -1.8764e-04,  1.0070e-03,\n",
       "         -8.6190e-05,  4.0728e-05, -6.4185e-05, -6.5544e-06,  1.5683e-04,\n",
       "         -8.7214e-05, -1.2480e-04, -2.2715e-04,  4.6720e-04,  2.5202e-04,\n",
       "          5.9424e-04, -1.3183e-04, -1.0324e-04, -2.3870e-04, -1.9941e-04,\n",
       "         -4.4352e-05,  4.8838e-05, -1.3998e-04,  2.0821e-04,  3.2660e-05,\n",
       "         -7.8106e-05,  2.5648e-05, -6.7547e-06, -4.3869e-05,  4.7656e-05,\n",
       "         -4.3354e-04, -1.3280e-04, -3.8935e-04,  4.0014e-04, -2.3305e-04,\n",
       "          6.4592e-05,  5.0493e-05, -2.0165e-04, -2.3619e-04,  1.2692e-04,\n",
       "          1.6583e-04, -4.2725e-05, -1.8902e-04, -1.2951e-04,  9.8915e-05,\n",
       "         -1.6726e-04, -1.8822e-04, -4.3388e-05,  1.8037e-04,  2.4596e-04,\n",
       "          2.3458e-07, -6.0441e-05, -4.7840e-05,  2.8895e-04,  5.8107e-05,\n",
       "          1.9344e-04,  1.3739e-04,  1.0436e-03,  3.1149e-05,  7.2558e-04,\n",
       "         -4.7888e-04, -2.1113e-04, -3.4209e-05, -1.3404e-04, -3.5102e-04,\n",
       "          3.3850e-04, -2.2088e-04, -5.8919e-05,  9.9944e-04, -2.2811e-05,\n",
       "          9.2249e-05,  9.0278e-06, -2.5923e-04,  7.2947e-05, -4.6946e-06,\n",
       "          3.9035e-06, -5.7401e-04,  4.8220e-04,  4.1181e-04,  7.0581e-04,\n",
       "          3.9257e-05, -3.4638e-05, -2.9497e-04,  1.9379e-03,  5.2214e-04,\n",
       "         -3.3552e-03, -2.5069e-03,  2.4839e-03, -2.1372e-04,  6.1577e-04,\n",
       "         -8.3861e-04,  4.1509e-04, -2.2731e-04,  1.7767e-03, -2.3549e-03,\n",
       "         -2.2994e-03,  1.9028e-03,  2.1784e-03, -4.2561e-03,  1.2279e-03,\n",
       "          6.7445e-04,  1.1403e-03, -2.8967e-03,  1.2213e-03, -2.3161e-03,\n",
       "         -9.3880e-04, -4.6755e-03, -8.5408e-04,  1.3968e-03,  2.0438e-03,\n",
       "          6.6126e-04,  2.0045e-03,  1.1275e-03,  1.7624e-03, -1.0083e-03,\n",
       "         -4.6739e-04, -1.6472e-03,  9.6356e-04,  1.7467e-03, -2.3869e-03,\n",
       "         -4.0434e-03,  4.0818e-03,  4.6161e-04,  4.1438e-03, -3.7281e-03,\n",
       "          2.6674e-03,  7.0962e-04,  9.2065e-04, -7.2187e-03,  3.7821e-03,\n",
       "         -5.9205e-03,  1.4583e-03, -3.4386e-03,  1.4243e-04, -4.8681e-04,\n",
       "         -4.5865e-04, -4.3392e-03, -6.6932e-04,  4.3304e-03, -2.2321e-03,\n",
       "         -1.0272e-02,  2.0783e-03, -2.0118e-03, -2.5710e-03,  2.7020e-03,\n",
       "          1.3649e-04,  1.3429e-03, -2.2504e-04, -8.4656e-05, -9.4676e-05,\n",
       "          1.0831e-04,  3.0370e-04,  2.0320e-05, -1.7318e-05,  1.8115e-06,\n",
       "          1.7531e-05,  5.0115e-06,  8.8513e-05, -6.0066e-04, -1.5698e-04,\n",
       "         -4.8754e-04,  4.7198e-04, -1.5527e-04,  1.1117e-04,  2.3649e-05,\n",
       "         -3.7365e-04, -1.2461e-04,  1.1056e-04, -9.5633e-05, -2.4991e-04,\n",
       "         -2.3918e-04, -1.4292e-04, -6.9687e-05, -1.0400e-04, -3.2470e-04,\n",
       "         -5.5425e-05,  2.9229e-04,  2.0147e-04, -9.9070e-05, -7.5148e-05,\n",
       "         -1.6032e-05,  5.0432e-04,  1.4428e-04,  2.7564e-04, -1.8470e-04,\n",
       "          1.4238e-03,  6.3826e-05,  3.8633e-04, -5.7065e-04, -3.5768e-04,\n",
       "         -1.1702e-04, -1.1926e-04,  2.9555e-04,  6.6493e-04, -6.9183e-04,\n",
       "         -3.1257e-04,  1.3849e-03, -7.5423e-05,  2.4348e-05, -6.3991e-05,\n",
       "         -1.1975e-05,  1.7762e-04,  7.4056e-05, -8.1608e-05, -4.6588e-04,\n",
       "          4.7420e-04,  3.4089e-04,  1.1444e-03, -8.4870e-05, -8.6207e-05,\n",
       "         -6.0877e-04]),\n",
       " tensor([-1.2702e-04, -6.0000e-05, -4.9699e-05,  1.4435e-04,  3.7387e-04,\n",
       "          3.2760e-05, -2.2994e-05,  5.1977e-05,  2.3162e-05, -8.3897e-07,\n",
       "          9.6787e-05, -4.0692e-04, -1.2392e-04, -5.3713e-04,  5.1452e-04,\n",
       "         -1.0483e-04,  1.2323e-04,  4.4483e-05, -2.2620e-04, -1.4437e-04,\n",
       "          1.3898e-04,  7.3699e-06, -1.6570e-04, -1.1200e-04, -1.0253e-04,\n",
       "         -8.6140e-05, -7.6131e-05, -1.7618e-04, -1.0142e-04,  1.9683e-04,\n",
       "          1.9060e-04, -7.5373e-05, -6.2845e-05, -4.8453e-05,  2.2551e-04,\n",
       "          1.4130e-04,  1.2706e-04, -1.2890e-04,  1.0814e-03,  6.2642e-05,\n",
       "          2.7289e-04, -4.9046e-04, -3.8368e-04, -1.1005e-04, -9.4567e-05,\n",
       "         -4.7188e-06,  7.5073e-04, -7.2997e-04, -1.8764e-04,  1.0070e-03,\n",
       "         -8.6190e-05,  4.0728e-05, -6.4185e-05, -6.5544e-06,  1.5683e-04,\n",
       "         -8.7214e-05, -1.2480e-04, -2.2715e-04,  4.6720e-04,  2.5202e-04,\n",
       "          5.9424e-04, -1.3183e-04, -1.0324e-04, -2.3870e-04, -1.9941e-04,\n",
       "         -4.4352e-05,  4.8838e-05, -1.3998e-04,  2.0821e-04,  3.2660e-05,\n",
       "         -7.8106e-05,  2.5648e-05, -6.7547e-06, -4.3869e-05,  4.7656e-05,\n",
       "         -4.3354e-04, -1.3280e-04, -3.8935e-04,  4.0014e-04, -2.3305e-04,\n",
       "          6.4592e-05,  5.0493e-05, -2.0165e-04, -2.3619e-04,  1.2692e-04,\n",
       "          1.6583e-04, -4.2725e-05, -1.8902e-04, -1.2951e-04,  9.8915e-05,\n",
       "         -1.6726e-04, -1.8822e-04, -4.3388e-05,  1.8037e-04,  2.4596e-04,\n",
       "          2.3458e-07, -6.0441e-05, -4.7840e-05,  2.8895e-04,  5.8107e-05,\n",
       "          1.9344e-04,  1.3739e-04,  1.0436e-03,  3.1149e-05,  7.2558e-04,\n",
       "         -4.7888e-04, -2.1113e-04, -3.4209e-05, -1.3404e-04, -3.5102e-04,\n",
       "          3.3850e-04, -2.2088e-04, -5.8919e-05,  9.9944e-04, -2.2811e-05,\n",
       "          9.2249e-05,  9.0278e-06, -2.5923e-04,  7.2947e-05, -4.6946e-06,\n",
       "          3.9035e-06, -5.7401e-04,  4.8220e-04,  4.1181e-04,  7.0581e-04,\n",
       "          3.9257e-05, -3.4638e-05, -2.9497e-04,  1.9379e-03,  5.2214e-04,\n",
       "         -3.3552e-03, -2.5069e-03,  2.4839e-03, -2.1372e-04,  6.1577e-04,\n",
       "         -8.3861e-04,  4.1509e-04, -2.2731e-04,  1.7767e-03, -2.3549e-03,\n",
       "         -2.2994e-03,  1.9028e-03,  2.1784e-03, -4.2561e-03,  1.2279e-03,\n",
       "          6.7445e-04,  1.1403e-03, -2.8967e-03,  1.2213e-03, -2.3161e-03,\n",
       "         -9.3880e-04, -4.6755e-03, -8.5408e-04,  1.3968e-03,  2.0438e-03,\n",
       "          6.6126e-04,  2.0045e-03,  1.1275e-03,  1.7624e-03, -1.0083e-03,\n",
       "         -4.6739e-04, -1.6472e-03,  9.6356e-04,  1.7467e-03, -2.3869e-03,\n",
       "         -4.0434e-03,  4.0818e-03,  4.6161e-04,  4.1438e-03, -3.7281e-03,\n",
       "          2.6674e-03,  7.0962e-04,  9.2065e-04, -7.2187e-03,  3.7821e-03,\n",
       "         -5.9205e-03,  1.4583e-03, -3.4386e-03,  1.4243e-04, -4.8681e-04,\n",
       "         -4.5865e-04, -4.3392e-03, -6.6932e-04,  4.3304e-03, -2.2321e-03,\n",
       "         -1.0272e-02,  2.0783e-03, -2.0118e-03, -2.5710e-03,  2.7020e-03,\n",
       "          1.3649e-04,  1.3429e-03, -2.2504e-04, -8.4656e-05, -9.4676e-05,\n",
       "          1.0831e-04,  3.0370e-04,  2.0320e-05, -1.7318e-05,  1.8115e-06,\n",
       "          1.7531e-05,  5.0115e-06,  8.8513e-05, -6.0066e-04, -1.5698e-04,\n",
       "         -4.8754e-04,  4.7198e-04, -1.5527e-04,  1.1117e-04,  2.3649e-05,\n",
       "         -3.7365e-04, -1.2461e-04,  1.1056e-04, -9.5633e-05, -2.4991e-04,\n",
       "         -2.3918e-04, -1.4292e-04, -6.9687e-05, -1.0400e-04, -3.2470e-04,\n",
       "         -5.5425e-05,  2.9229e-04,  2.0147e-04, -9.9070e-05, -7.5148e-05,\n",
       "         -1.6032e-05,  5.0432e-04,  1.4428e-04,  2.7564e-04, -1.8470e-04,\n",
       "          1.4238e-03,  6.3826e-05,  3.8633e-04, -5.7065e-04, -3.5768e-04,\n",
       "         -1.1702e-04, -1.1926e-04,  2.9555e-04,  6.6493e-04, -6.9183e-04,\n",
       "         -3.1257e-04,  1.3849e-03, -7.5423e-05,  2.4348e-05, -6.3991e-05,\n",
       "         -1.1975e-05,  1.7762e-04,  7.4056e-05, -8.1608e-05, -4.6588e-04,\n",
       "          4.7420e-04,  3.4089e-04,  1.1444e-03, -8.4870e-05, -8.6207e-05,\n",
       "         -6.0877e-04])]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.grad for x in list(model.encoder.parameters())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=config.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.training.trainer import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    iterator=iterator,\n",
    "    train_dataset=train_ds,\n",
    "    cuda_device=0 if USE_GPU else -1,\n",
    "    num_epochs=config.epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.6856 ||: 100%|██████████| 5/5 [00:29<00:00,  6.91s/it]\n",
      "loss: 0.6498 ||: 100%|██████████| 5/5 [00:29<00:00,  6.10s/it]\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.iterators import DataIterator\n",
    "from tqdm import tqdm\n",
    "from scipy.special import expit # the sigmoid function\n",
    "\n",
    "def tonp(tsr): return tsr.detach().cpu().numpy()\n",
    "\n",
    "class Predictor:\n",
    "    def __init__(self, model: Model, iterator: DataIterator,\n",
    "                 cuda_device: int=-1) -> None:\n",
    "        self.model = model\n",
    "        self.iterator = iterator\n",
    "        self.cuda_device = cuda_device\n",
    "        \n",
    "    def _extract_data(self, batch) -> np.ndarray:\n",
    "        out_dict = self.model(**batch)\n",
    "        return expit(tonp(out_dict[\"class_logits\"]))\n",
    "    \n",
    "    def predict(self, ds: Iterable[Instance]) -> np.ndarray:\n",
    "        pred_generator = self.iterator(ds, num_epochs=1, shuffle=False)\n",
    "        self.model.eval()\n",
    "        pred_generator_tqdm = tqdm(pred_generator,\n",
    "                                   total=self.iterator.get_num_batches(ds))\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for batch in pred_generator_tqdm:\n",
    "                batch = nn_util.move_to_device(batch, self.cuda_device)\n",
    "                preds.append(self._extract_data(batch))\n",
    "        return np.concatenate(preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.iterators import BasicIterator\n",
    "# iterate over the dataset without changing its order\n",
    "seq_iterator = BasicIterator(batch_size=64)\n",
    "seq_iterator.index_with(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:37<00:00,  6.85s/it]\n",
      "100%|██████████| 4/4 [00:34<00:00,  8.58s/it]\n"
     ]
    }
   ],
   "source": [
    "predictor = Predictor(model, seq_iterator, cuda_device=0 if USE_GPU else -1)\n",
    "train_preds = predictor.predict(train_ds) \n",
    "test_preds = predictor.predict(test_ds) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
